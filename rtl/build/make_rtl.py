#!/usr/bin/env python3

################################################################################
# make_rtl.py
# Author: Zachary Susskind (ZSusskind@utexas.edu)
#
# Makes RTL headers and invokes render_template.py to make RTL sources
#
#
# MIT License
# 
# Copyright (c) 2024 The University of Texas at Austin
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
################################################################################

import os
import sys
import math
import lzma
import pickle
import argparse
import numpy as np
from textwrap import dedent
from render_template import render_template_file
from numpy import flip, log2

sys.path.append("../backprop_experiments/binary_model/")
sys.path.append("../software_model/")
from finalize_model import EnsembleWiSARD, WiSARD, Discriminator, BloomFilter

build_dirname = os.path.dirname(__file__)
sv_dirname = os.path.join(build_dirname, "../sv_srcs")
sys.path.append(os.path.join(build_dirname, "../../software_model"))

parser = argparse.ArgumentParser()
parser.add_argument("filenames", nargs="+", help="List of templated .sv.mako files to convert")
parser.add_argument("--model", required=True, help="Pointer to the model .pickle.lzma file")
parser.add_argument("--compressed", action="store_true", help="Whether input data is compressed")
parser.add_argument("--bus_width", type=int, default=64, help="Width of the input data bus")
parser.add_argument("--throughput", type=int, default=-1, help="Target model throughput in cycles; defaults to maximum possible given bus constraint")
args = parser.parse_args()

config = {"compressed_input": args.compressed, "bus_width": args.bus_width, "throughput": args.throughput}

with lzma.open(args.model, "rb") as f:
  state_dict = pickle.load(f)
info = state_dict["info"]
model = state_dict["model"]

os.makedirs(sv_dirname, exist_ok=True)

# Generate SV header files
header_text = dedent("""\
    ////////////////////////////////////////////////////////////////////////////////
    // THIS FILE WAS AUTOMATICALLY GENERATED BY make_rtl.py
    // DO NOT EDIT
    ////////////////////////////////////////////////////////////////////////////////

""")

model_parameter_strings = []
model_parameter_strings.append("// FILTER DATA")
for submodel_idx, submodel in enumerate(model.wisard_models):
    for discrim_idx, discrim in enumerate(submodel.discriminators):
        model_parameter_strings.append(f"// M{submodel_idx}D{discrim_idx}")
        for bfilter_idx, bfilter in discrim.nonsparse_filters.items():
            name = f"FDATA_{submodel_idx}_{discrim_idx}_{bfilter_idx}"
            size = bfilter.data.size
            data = "".join(str(b) for b in np.flip(bfilter.data).astype("u1").tolist()) # Need to reorder from MSB to LSB
            model_parameter_strings.append(f"`define {name} {size}'b{data}")
model_parameter_strings.append("\n// HASH VALUES")
for submodel_idx, submodel_info in enumerate(info["submodel_info"]):
    hash_parameter_name = f"HPARAMS_{submodel_idx}"
    hash_parameter_element_size = int(log2(submodel_info["num_filter_entries"]))
    hash_parameter_data = f"{submodel_info['hash_values'].size*hash_parameter_element_size}'b"
    for hash_idx, hash_params in reversed(list(enumerate(submodel_info["hash_values"]))):
        for p in flip(hash_params):
            hash_parameter_data += bin(p)[2:].zfill(hash_parameter_element_size)
    model_parameter_strings.append(f"`define {hash_parameter_name} {hash_parameter_data}")

parameter_header_fname = os.path.join(sv_dirname, "model_parameters.svh")
parameter_header_string = header_text + "\n".join(model_parameter_strings)
with open(parameter_header_fname, "w") as f:
    f.write(parameter_header_string)

num_unique_inputs = int(info["num_inputs"] / info["bits_per_input"])
compressed_input_size = math.ceil(math.log2(info["bits_per_input"]+1))
compressed_size = compressed_input_size * num_unique_inputs
input_size = compressed_size if args.compressed else info["num_inputs"]
config_strings = [
    f"`define INPUT_BUS_WIDTH {args.bus_width}",
    f"`define INPUT_SIZE_BITS {input_size}"
]
config_header_fname = os.path.join(sv_dirname, "config.svh")
config_header_string = header_text + "\n".join(config_strings)
with open(config_header_fname, "w") as f:
    f.write(config_header_string)

# Render all template files
for in_fname in args.filenames:
    dirname, basename = os.path.split(in_fname)
    out_dirname = os.path.join(dirname, "../sv_srcs")
    out_fname = os.path.join(out_dirname, basename.rstrip(".mako"))
    print(f"Rendering {basename}")
    render_template_file(in_fname, out_fname, info, config)

